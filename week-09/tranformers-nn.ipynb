{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a58363",
   "metadata": {},
   "source": [
    "### The Premise\n",
    "\n",
    "Imagine a super librarian in a magical library where books can talk to each other. This librarian’s job is to translate a story from one language to another or generate a continuation of a story. The library is full of words, and each word is like a book with its own meaning and position in the story.  \n",
    "\n",
    "### The Problem\n",
    "When the librarian reads a sentence like “Hi, how are you?”, they need to understand which words are most important to generate a response like “I am fine.” Unlike older librarians (like Recurrent Neural Networks, or RNNs), who could only remember a few words at a time and forgot the beginning of long stories, this super librarian can pay attention to all words at once, no matter how long the story is.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. Word Books (Embeddings)\n",
    "2. Position Tags (Positional Encoding)\n",
    "3. Attention Magic (Self-Attention)\n",
    "4. Teamwork (Multi-Headed Attention)\n",
    "5. Processing and Refining (Feed-Forward Layers)\n",
    "6. Translating or Generating (Encoder-Decoder)\n",
    "    - Encoder: Reads and creates summary with attention scores\n",
    "    - Decoder: Uses the summary to generate a word-by-word output\n",
    "7. Final Touch (Softmax)\n",
    "\n",
    "### Why It's Useful\n",
    "\n",
    "Unlike older librarians (RNNs), who could only hold a short piece of the story in their memory, the super librarian’s attention magic lets them reference the entire story at once. This makes them great at tasks like translating languages, writing stories, or answering questions, even for very long texts.  \n",
    "\n",
    "\n",
    "This *super librarian* is the **Transformer**, and its attention magic is why it’s so powerful in natural language processing (NLP) tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4554d54d",
   "metadata": {},
   "source": [
    " The project below implements a simplified Transformer model to reverse a sequence of numbers (e.g., `[1, 2, 3, 4, 5]` → `[5, 4, 3, 2, 1]`) as practice to mimic sequence-to-sequence problems like translation. Using NumPy, it demonstrates the core components of a Transformer (embeddings, positional encoding, self-attention, multi-head attention, feed-forward layers, encoder, and decoder) without actual training, focusing on the architecture’s mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ec3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = 10  # Numbers 0-9\n",
    "d_model = 8      # Embedding dimension\n",
    "n_heads = 2      # Number of attention heads\n",
    "d_ff = 16        # Feed-forward dimension\n",
    "seq_length = 5   # Sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a067ee8e",
   "metadata": {},
   "source": [
    "We use NumPy for matrix operations.  \n",
    "\n",
    "The hyperparameters define the model size:  \n",
    "`vocab_size` is the range of input numbers,  \n",
    "`d_model` is the embedding size,  \n",
    "`n_heads` splits attention,  \n",
    "`d_ff` is the feed-forward layer size, and  \n",
    "`seq_length` is the input sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c8f8f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input: [6 3 7 4 6]\n",
      "Example output: [6 4 7 3 6]\n",
      "\n",
      "Data shape: (100, 5) (100, 5)\n"
     ]
    }
   ],
   "source": [
    "def generate_data(num_samples, seq_length, vocab_size):\n",
    "    \"\"\"Generate random sequences and their reversed versions.\"\"\"\n",
    "    X = np.random.randint(0, vocab_size, (num_samples, seq_length))\n",
    "    y = np.flip(X, axis=1)\n",
    "    return X, y\n",
    "\n",
    "# Generate 100 samples\n",
    "X, y = generate_data(100, seq_length, vocab_size)\n",
    "print(\"Example input:\", X[0])\n",
    "print(\"Example output:\", y[0])\n",
    "\n",
    "print(\"\\nData shape:\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8673ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (1, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(X, vocab_size, d_model):\n",
    "    \"\"\"Convert numbers to dense embeddings.\"\"\"\n",
    "    # Random embedding matrix\n",
    "    embedding_matrix = np.random.randn(vocab_size, d_model) * 0.1\n",
    "    # Lookup embeddings for input sequence\n",
    "    return np.array([embedding_matrix[x] for x in X])\n",
    "\n",
    "# Test embeddings\n",
    "X_emb = get_embeddings(X[:1], vocab_size, d_model)\n",
    "print(\"Embedding shape:\", X_emb.shape)  # (1, seq_length, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee708573",
   "metadata": {},
   "source": [
    "Each number is mapped to a dense vector (embedding) of size `d_model`. In NLP, these are learned word vectors; here, we use a random matrix for simplicity. The output shape is `(batch_size, seq_length, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86ad54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional encoding shape: (1, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "def positional_encoding(seq_length, d_model):\n",
    "    \"\"\"Add positional information to embeddings.\"\"\"\n",
    "    pos = np.arange(seq_length)[:, np.newaxis]\n",
    "    dim = np.arange(d_model)[np.newaxis, :]\n",
    "    angle = pos / np.power(10000, (2 * (dim // 2)) / d_model)\n",
    "    angle[:, 0::2] = np.sin(angle[:, 0::2])\n",
    "    angle[:, 1::2] = np.cos(angle[:, 1::2])\n",
    "    return angle[np.newaxis, :, :]\n",
    "\n",
    "# Add positional encoding to embeddings\n",
    "pos_enc = positional_encoding(seq_length, d_model)\n",
    "X_emb_with_pos = X_emb + pos_enc\n",
    "print(\"Positional encoding shape:\", pos_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77ce72",
   "metadata": {},
   "source": [
    "Since Transformers process all tokens simultaneously, we add positional encodings to embeddings to indicate word order. We use sine and cosine functions, as in the original Transformer paper, to create unique position vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a97ba9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention output shape: (1, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    \"\"\"Compute scaled dot-product attention for single or multi-head inputs.\"\"\"\n",
    "    d_k = Q.shape[-1]\n",
    "    if Q.ndim == 4:  # Multi-head: (batch, n_heads, seq_length, d_k)\n",
    "        scores = np.matmul(Q, K.transpose(0, 1, 3, 2)) / np.sqrt(d_k)\n",
    "    else:  # Single-head: (batch, seq_length, d_model)\n",
    "        scores = np.matmul(Q, K.transpose(0, 2, 1)) / np.sqrt(d_k)\n",
    "    # Softmax over last dimension\n",
    "    weights = np.exp(scores) / np.sum(np.exp(scores), axis=-1, keepdims=True)\n",
    "    output = np.matmul(weights, V)\n",
    "    return output, weights\n",
    "\n",
    "# Test attention\n",
    "Q, K, V = X_emb_with_pos, X_emb_with_pos, X_emb_with_pos\n",
    "attn_output, attn_weights = scaled_dot_product_attention(Q, K, V)\n",
    "print(\"Attention output shape:\", attn_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb8c59",
   "metadata": {},
   "source": [
    "Self-attention computes how much each token attends to every other token. Queries (`Q`), keys (`K`), and values (`V`) are derived from the input. Scaled dot-product attention normalizes scores by the square root of the key dimension to stabilize gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40c7bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-head attention output shape: (1, 5, 8)\n",
      "Attention weights shape: (1, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "def multi_head_attention(X, n_heads, d_model):\n",
    "    \"\"\"Split embeddings into multiple heads, apply attention, and concatenate.\"\"\"\n",
    "    d_k = d_model // n_heads\n",
    "    # Reshape for multiple heads: (batch, seq_length, d_model) -> (batch, seq_length, n_heads, d_k)\n",
    "    X_heads = X.reshape(X.shape[0], X.shape[1], n_heads, d_k)\n",
    "    # Transpose to (batch, n_heads, seq_length, d_k)\n",
    "    Q = K = V = X_heads.transpose(0, 2, 1, 3)\n",
    "    # Apply attention\n",
    "    attn_output, attn_weights = scaled_dot_product_attention(Q, K, V)\n",
    "    # Concatenate heads: (batch, n_heads, seq_length, d_k) -> (batch, seq_length, n_heads * d_k)\n",
    "    attn_output = attn_output.transpose(0, 2, 1, 3).reshape(X.shape[0], X.shape[1], d_model)\n",
    "    # Linear projection\n",
    "    W_o = np.random.randn(d_model, d_model) * 0.1\n",
    "    output = np.matmul(attn_output, W_o)\n",
    "    return output, attn_weights\n",
    "\n",
    "# Test multi-head attention\n",
    "mha_output, attn_weights = multi_head_attention(X_emb_with_pos, n_heads, d_model)\n",
    "print(\"Multi-head attention output shape:\", mha_output.shape)\n",
    "print(\"Attention weights shape:\", attn_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16743afa",
   "metadata": {},
   "source": [
    "Multi-head attention splits the embedding into `n_heads` parts, applies attention independently, and concatenates results. This allows the model to focus on different aspects of the input simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b853ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights shape: (1, 2, 5, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxgAAAFvCAYAAADJxW00AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAARn9JREFUeJzt3Qd4VNXW8PEVSkIJobfQkSYoRdpFiggIIoIoTS6vBPCiV0HFKFd5PyUgIOUioMIFBQUVEVSKioqUFxAVpIkiCALSew9FKcl8z9o6czNkApnJSWbmnP/veY6ZOXPmzB7AfbLO2nvtCJfL5RIAAAAAsEA2K04CAAAAAIoAAwAAAIBlCDAAAAAAWIYAAwAAAIBlCDAAAAAAWIYAAwAAAIBlCDAAAAAAWIYAAwAAAIBlCDAAAAAAWIYAA0hDr169pHz58sFuBgCENfpSwHkIMBBUM2bMkIiICFm/fr3P15s3by633HKLhLK1a9fK448/LnXr1pWcOXOa7wMAWSnc+9Lk5GTzHTp06CBlypSRvHnzmvYOHz5c/vjjj2A3D4CfCDCADPriiy9k2rRp5uJesWLFYDcHAMLOxYsXpXfv3nL8+HH55z//KRMmTJAGDRpIQkKCtG3bVlwuV7CbCMAPOfw5GEBqjz32mDz33HOSO3du6d+/v/z666/BbhIAhJXIyEj59ttv5fbbb/fs69u3rxlapUHGsmXLpFWrVkFtI4D0I4OBsDRz5kwzJEl/qS9UqJA8+OCDsn//fq9jVq1aJV26dJGyZctKVFSUSbs//fTT8vvvv6c634IFC0w6PleuXObn/Pnz092W4sWLm3YAQLgJlb5UA4yUwYXb/fffb37+8ssvAX9HAFmPDAZCwtmzZ+XEiROp9l+5ciXVvhEjRsiLL74oXbt2lX/84x8mpf76669Ls2bN5IcffpACBQqY4z766COTdtcMQ+HChc1cCT3uwIED5jW3xYsXS6dOnaR69eoycuRIOXnypEnVly5dOpO/NQBYy2596ZEjR8zPIkWKBHwOAEHgAoJo+vTpOrD2uluNGjU8x+/Zs8eVPXt214gRI7zOs3nzZleOHDm89l+8eDHV540cOdIVERHh2rt3r2df7dq1XSVLlnSdOXPGs2/x4sXms8uVK+fX9+nXr595HwBkJbv1pW6tWrVyxcTEuE6fPh3Q+wEEBxkMhIRJkyZJlSpVUu1/5plnJCkpyfN83rx5ptqI3nFLeZeuRIkSUrlyZVm+fLn87//+r9mXctjShQsXTDpfU/A6WVDvzmm6//Dhw7Jp0yZ5/vnnJX/+/J7j77rrLnMXTt8HAOHCTn3pyy+/LEuXLpX//Oc/nmwKgPBAgIGQoNVC6tWrl2p/wYIFvS5+O3bsMBc1vQD6omVi3fbt2yeDBw+WTz/9VE6fPp1qGIHau3ev+enrfFWrVpWNGzdm4FsBQNayS186Z84ceeGFF+Thhx82Q7OAzKSlkC9fvhzQe3X+kM45gjcCDIQVveOm5WC//PJLyZ49e6rXo6OjzU+9U6d3zk6dOmUqPFWrVs3UVT948KBZ9EnPAwBOFcp96ZIlS6Rnz57Srl07mTJliuXnB64NLipUqOCZ7+Mvzfrt3r2bIOMaBBgIKzfddJO566adga9hAG6bN2825WLfeecdc6FKeeFKqVy5cp67edfavn27pW0HgFARqn3p999/bypHaRbmww8/lBw5+DUFmUszFxpc7N+/W2JiYvx6b2JiopQpU8GcgwDDG2VqEVYeeOABc7dt6NChqRZe0udatUS578ilPEYfv/rqq17vKVmypNSuXdtcPN2pfvfFc+vWrZn8bQAgOEKxL9VStJq10LUvFi5cSPlvZKmYmDwBbfCNWwMIu7tuw4cPl0GDBsmePXukY8eOki9fPpOe1HrrjzzyiDz77LMmja/H6mNN5etdiblz56YaP6y0nKJe1Jo0aSJ9+vQxQwG0BGONGjXk/PnzN2yTjj1+7733zOP169ebn9pG9129hx56yPI/BwCwU1967tw5adOmjTnvwIED5fPPP0/V3kaNGln+5wD819W/Nn/fA5+CVL0K8CqtuG7dOp+v33HHHV6lFd3mzp3ratKkiStv3rxmq1atmikRu337ds8xW7duNSUOo6OjXUWKFHH17dvX9eOPP5rP08+99nw333yzKyoqylW9enXXvHnzXHFxcekqrbh8+fI0y0Jq+wEgs4V7X7p79+7rltjVcwCZ4ezZs+bf2NmzB10u1zm/Nn3Pn+8969dnTpw40fw/of+fNGjQwPX999+neeybb75p/h8tUKCA2Vq2bJnq+ISEBFfVqlVdefLk8RyzZs0aVzBF6H98hx4AAACAfek8Ci2tfPbs3oDmYOTPX84MC0zve+fMmWPmM2kBg4YNG8qECRPMgpU6V6lYsWKpju/Ro4c0btzYlIbWeR6jR482WcYtW7ZIqVKlzDGzZs0y761YsaIpIz1+/Hhzzp07d0rRokUlGAgwAAAA4PAA4zeJicnn53vPSf78Ff0KMBo2bCj169eXiRMnmudaia1MmTLyxBNPmHVkbkQru2nZaX1/ysILvr6TriPTsmVLCQYmeQMAAMDhrga4pd/ly5dlw4YN0qpVK8++bNmymeerV69O1zkuXrwoV65ckUKFCqX5GW+++aYJMGrVqiXBwiRvAAAAOFzgk7w1Y5BSVFSU2a6li11qBqJ48eJe+/X5tm3b0vWJuh5NbGysV5CitPLagw8+aAIQreqmFdyKFCkiwUIGAwAAAA4XeAZDhzhpxsC9jRw5MlNaOGrUKJk9e7aZg3Htuht33nmnbNq0Sb777ju5++67pWvXrnLs2DEJFjIYAAAAQID279/vNQcjykf2QmlGQdeWOXr0qNd+fa4rgl/P2LFjTYCh8ypq1qyZ6vW8efNKpUqVzPa3v/1NKleuLG+99ZYpRR0MZDAAAADgcEkBbrpIX4zXFpVGgBEZGSl169aVZcuWefbpJG99fr11XsaMGSPDhg2TRYsWmVXu00PPe+nSJQmWsM5g6B/eoUOHzOJAERERwW4OABvSQnu6CJiOedXJeHZDPwogs4VHP5oUwByMPwMMf8THx0tcXJwJFBo0aGDK1F64cEF69+5tXtfKUFp+1j3MSsvSDh482JSi1VXujxw5YvZHR0ebTd87YsQI6dChg5l7ofM8Jk2aZBbG7NKliwRLWAcYelHUcW8AkBUp8NKlS4vd0I8CyCqh3Y9mzUre3bp1k+PHj5ugQYOF2rVrm8yEe+L3vn37vIKwyZMnm8pQnTt39jpPQkKCDBkyxAy50gni77zzjgkuChcubMrgrlq1SmrUqCHBEtbrYGjd4QIFCqQa+2Yrk/OL3aWj7HNY+0nsr6nYlyaYx4vImTNnzOQ9u3H3o6NFxHvKoH30Outfbfuw9Pw5sbWGYn9vim0lXhUpszY0+9H/roPxjcTERPv53vOSP38Tv9bBcIqwzmC40/nuMW+2ZNcrfgq+RyraR1j/T5ZODvhnatvhQ+7vpX+HucWeYmLs+XfnqI40j9ifAy4Wod2PZk0GwylCdSAcAAAAgDDkgHgZAAAACP4kb6cgwAAAAIDDMUTKSgQYAAAAcDgCDCsRYAAAAMDhCDCsRIABAAAAhyPAsBJVpAAAAABYhgwGAAAAHI4qUlYiwAAAAIDDMUTKSgQYAAAAcDgCDCsRYAAAAMDhCDCsRIABAAAAhyPAsBJVpAAAAABYhgwGAAAAHI4qUlYiwAAAAIDDJQUQMBBgpIUAAwAAAA7HHAwrEWAAAADA4QgwrMQkbwAAAACWIYMBAAAAh2OSt5UIMAAAAOBwDJGyEgEGAAAAHI4AwzZzML7++mtp3769xMbGSkREhCxYsCCYzQGAsEM/CgBWBhj+bgi5AOPChQtSq1YtmTRpUjCbAQBhi34UAKxAgGGbIVJt27Y1GwAgMPSjAIBQE1ZzMC5dumQ2t8TExKC2BwDCDf0oAPhCFSnHroMxcuRIyZ8/v2crU6ZMsJsEAGGFfhQAfGGIlGMDjEGDBsnZs2c92/79+4PdJAAIK/SjAOALAYZjh0hFRUWZDQAQGPpRAPBFg4XsAbwHYR9gAAAAANZjDoZtAozz58/Lzp07Pc93794tmzZtkkKFCknZsmWD2TQACAv0owCAUBPUAGP9+vVy5513ep7Hx8ebn3FxcTJjxowgtgwAwgP9KABY4WoAU5MZIhWSAUbz5s3F5XIFswkAENboRwHACgQYVmIOBgAAAByOAMNKBBgAAABwuKQAJm0zyTstBBgAAABwOKpIOXahPQAAACCcTZo0ScqXLy+5cuWShg0bytq1a9M8durUqdK0aVMpWLCg2Vq1auV1/JUrV+S5556TW2+9VfLmzSuxsbHSs2dPOXTokAQTAQYAAAAcLmtW8p4zZ46p9peQkCAbN26UWrVqSZs2beTYsWM+j1+xYoV0795dli9fLqtXr5YyZcpI69at5eDBg+b1ixcvmvO8+OKL5ue8efNk+/bt0qFDBwkmhkgBAADA4TRYiAjgPf4ZN26c9O3bV3r37m2eT5kyRT7//HN5++235fnnn091/Pvvv+/1fNq0aTJ37lxZtmyZyVTkz59flixZ4nXMxIkTpUGDBrJv376grYdEBgMAAAAOF3gGIzEx0Wu7dOmSz0+4fPmybNiwwQxzcsuWLZt5rtmJ9NCMhQ6L0sVU03L27FmJiIiQAgUKSLAQYAAAAMDhAg8wdNiSZhLc28iRI31+wokTJyQpKUmKFy/utV+fHzlyJF2t1PkWOs8iZZCS0h9//GGO0WFVMTExEiwMkQIAAIDDJQUwROrPKlL79+/3+mU+KipKMsOoUaNk9uzZZl6GThC/lmY2unbtahZfnTx5sgQTAQYAAAAQIA0u0pMtKFKkiGTPnl2OHj3qtV+flyhR4rrvHTt2rAkwli5dKjVr1kwzuNi7d6/83//9X1CzF4ohUgAAAHC4zK8iFRkZKXXr1jUTtN2Sk5PN80aNGqX5vjFjxsiwYcNk0aJFUq9evTSDix07dpgApHDhwhJsZDAAAADgcFez5D3x8fESFxdnAgWt9DRhwgS5cOGCp6qUVoYqVaqUZx7H6NGjZfDgwTJr1iyzdoZ7rkZ0dLTZNLjo3LmzKVG7cOFCM8fDfYxOBNegJhgIMAAAAOBwWRNgdOvWTY4fP26CBg0EateubTIT7onfWlpWK0u56VwKrT6lQURKuo7GkCFDzHoYn376qdmn50pJ185o3ry5BAMBBgAAABwuKYveI9K/f3+z+aITuFPas2fPdc+lWQ2d1B1qCDAAAADgcJqNcGVJgOEETPIGAAAAYBkyGAAAAHA4MhhWIsAAAACAwxFgWIkAAwAAAA5HgGElAgwAAAA4XFIAAUZyJrUl/BFgAAAAwOEIMKxkjwBjbH6RXGJP94rtja8gtvbFbrG9MWJfgSy9FI6eF5EIsae+clZsr7pd//b+slns76LYFyOJHMceAQYAAACQodtJ/q7eQAYjLQQYAAAAcDgCDCsRYAAAAMDhCDCsRIABAAAAh0sKIGDwd1K4cxBgAAAAwOE0g+FvsQQCjLT4mwsCAAAAgDSRwQAAAIDDkcGwEgEGAAAAHI4Aw0oEGAAAAHA2V7L/8QLxRZoIMAAAAOBsyQEUkaJKbZoIMAAAAOBsSX9t/r4HPlFFCgAAAIBlyGAAAADA2chgWIoAAwAAAM7GHAxLEWAAAADA2chgWIoAAwAAAM5GBsNSBBgAAABwtuQAMhIEGGmiihQAAAAAy5DBAAAAgLMxB8NSBBgAAABwNuZgWIoAAwAAAM5GBsNSBBgAAABwNgIMSxFgAAAAwNkYImWfKlIjR46U+vXrS758+aRYsWLSsWNH2b59ezCbBABhhX4UABBqghpgrFy5Uvr16ydr1qyRJUuWyJUrV6R169Zy4cKFYDYLAMIG/SgAWDhEyt8NoTdEatGiRV7PZ8yYYe7AbdiwQZo1axa0dgFAuKAfBQALuAIY8qTvQejPwTh79qz5WahQIZ+vX7p0yWxuiYmJWdY2AAgH9KMAEAAmedtzJe/k5GQZMGCANG7cWG655ZY0xxrnz5/fs5UpUybL2wkAoYp+FAAC5NAhUn369JFz586l2q/DbPW1sA8wdAzxzz//LLNnz07zmEGDBpm7c+5t//79WdpGAAhl9KMAkMEqUv5uAZg0aZKUL19ecuXKJQ0bNpS1a9emeezUqVOladOmUrBgQbO1atUq1fHz5s0zc+8KFy4sERERsmnTpnS35Z133pHff/891X7d9+6770pYBxj9+/eXhQsXyvLly6V06dJpHhcVFSUxMTFeGwCAfhQAwsGcOXMkPj5eEhISZOPGjVKrVi1p06aNHDt2zOfxK1askO7du5u+ffXq1SbrrMHEwYMHvbINTZo0kdGjR6e7HTo8Vm8yuVwuk8HQ5+7t9OnT8sUXX5j5fGE5B0O/1BNPPCHz5883f4AVKlQIZnMAIOzQjwJA+MzBGDdunPTt21d69+5tnk+ZMkU+//xzefvtt+X5559Pdfz777/v9XzatGkyd+5cWbZsmfTs2dPse+ihh8zPPXv2pLsdBQoUMNkO3apUqZLqdd0/dOhQCcsAQ9P5s2bNkk8++cTUcD9y5IjZr+OCc+fOHcymAUBYoB8FgOAGGNcWy4iKijLbtS5fvmwq/OlQVbds2bKZYU+anUiPixcvmnLkaRXySC/NiOgNqhYtWpiAJeX5IiMjpVy5chIbGxueAcbkyZPNz+bNm3vtnz59uvTq1StIrQKA8EE/CgDBXcn72mIZCQkJMmTIkFSHnzhxQpKSkqR48eJe+/X5tm3b0vWRzz33nPnFX4OSjLjjjjvMz927d5v2a6BjpaAPkQIABI5+FAAskBxABuOvAEOLZaSczxblI3thhVGjRpkiHjocVieIW0EzFWfOnDETx3UeiFYjTMk9DCus18EAAAAAwimDkd6CGUWKFJHs2bPL0aNHvfbr8xIlSlz3vWPHjjUBxtKlS6VmzZpilc8++0x69Ogh58+fN99B51646eMsDTAyI9IBACehHwUAZ4mMjJS6deuaCdodO3Y0+7T/1+daCTAtY8aMkREjRshXX30l9erVs7RNzzzzjFnv4uWXX5Y8efJYdt4coRLpAIBT0I8CgDOrSMXHx0tcXJwJFBo0aCATJkwwZWbdVaW0/y9VqpRZFFVp6dnBgwebYh66doa7kEd0dLTZ1KlTp2Tfvn1y6NAh83z79u3mp2ZFbpQZ0XK3Tz75pKXBhcoWaKSjF0a9A6e1ct2bfkEAwPXRjwKAM1fy7tatmxnupEFD7dq1zaJ4ixYt8kz81kDh8OHDXoU8tPpU586dpWTJkp5Nz+H26aefSp06daRdu3bm+YMPPmieawncG9E1ONavXy9Wi3D5OUMwb968snnzZqlYsaIEm5YF01KMZ18UibFmrkvouVfs788soW19sVtsb4zY11UR+VbELEhk1aJ0odiPakHb/+ZR7OWCEybCT7Xr395fnLDg/JdiW4lJIvl/sLYftfx3yU9FYvL6+d4LIvk7hOb3uh4NSNyOHz8uL730ksmg3HrrrZIzZ06vYzt06CBZMkTKHemEwoURAMIR/SgAOHOIVChwz/9ISYOMa+mQXS2rmyUBhqZfBg4cKFu3brU00gEAp6AfBQAEy7WFRTKD3wGGLm+eGZEOADgF/SgAhBgHZTCyQo5QjHoAwM7oRwEgxOhULX+7ZhtM73rttdd87tebXbqYX6VKlaRZs2Zm/Q5/sNAeAAAAnM2hGYzx48ebid4XL16UggULmn1a0VDL1moZXF2rSecLLl++XMqUKZN5ZWrVypUrpX379iaq0U3HC69atSqQUwGAI9GPAkAIruTt7xbmXn75Zalfv77s2LFDTp48abZff/1VGjZsKK+++qopm6traTz99NN+ndfvAGPmzJnSqlUrE9nowhy65c6dW1q2bGkWAQEAXB/9KAA4cx2MUPPCCy+YLMZNN93k2ac3vXSdjUGDBknp0qXNSuLffqsF2zNxiJQuVa4flDKS0YvjuHHjZNiwYfL3v//d31MCgKPQjwIAQoEu6nf1qq745E33uVcNj42NlXPnzmVuBuO3334zaf1raXp/924HrCgGABlEPwoAIcahGYw777xTHn30Ufnhhx88+/TxY489Ji1atDDPdWHYChUqZG6AoRM8li1blmr/0qVL/Zr8AQBORT8KACHGoXMw3nrrLSlUqJDUrVtXoqKizFavXj2zT19TOtn7lVdeydwhUs8884xJ5W/atEluv/12s0/HZc2YMcNMBgEAXB/9KACEGIdWkSpRooQsWbJEtm3bZiZ3q6pVq5otZZbDX34HGJoy0cZoJPPhhx+afTfffLPMmTNH7rvvPr8bAABOQz8KACEmOYCAwQYZDLdq1aqZzSoBrYNx//33mw0AEBj6UQAIIYEMeQrTACM+Pt4UFMmbN695fD1afCQQLLQHAAAAOMQPP/wgV65c8TxOi67mHah0BRg60UPHZRUpUsSs8ne9Dzx16lTAjQEAu6IfBYAQ5qA5GMuXL/f52ErpCjB0AY58+fJ5HmckogEAJ6IfBYAQ5qAhUr7s3LlTdu3aJc2aNTMLv7pcrszPYMTFxXke9+rVK+APAwCnoh8FgBDmoAxGSidPnpSuXbuaTIYGFDt27JCKFSvKww8/bLLt/panDXgORvbs2c2qf8WKFUvVQN2XlJT1f9qDh4lEiT2N/ljs7ymxtXv+vGlta789LLb1u5aQtficodiP3mLrSXmfi+2VF3v7WezvjNhXONzpd2iA8fTTT0vOnDll3759ppqhW7du3cwE8CwLMDRl4sulS5ckMjIyoEYAgJPQjwJAiHHoEKnFixfLV199JaVLl/baX7lyZdm7d2/A5013gPHaa6+Zn5o+mTZtmlnVz03vtn399deW1s8FALuhHwUAhJILFy5Injx5fBYb0VW9Mz3A0EmJ7jtvU6ZMMSl+N73jVr58ebMfAOAb/SgAhCiHLrTXtGlTeffdd826GO4bYMnJyTJmzJiAVvD2O8DYvXu3+akfNm/ePDPxAwCQfvSjABCiHDpEasyYMdKyZUtZv369XL58Wf71r3/Jli1bTAbj228Dn4Ho9xyMzKqXCwBOQT8KACHGoZO8b7nlFtm+fbtMnDjRlFI/f/68PPDAA9KvXz8pWbJk5gYYWbGkOADYGf0oAIQwhwUYcXFxJnPRvHlzKVu2rLzwwguWnj9HqCwpDgB2Rj8KACHMYUOk9u7dK48++qgZFqXz/3TobosWLcxWokSJrAkwsmJJcQCwM/pRAECoWLFihSmN/t1335nHus2cOdPcCNMSte6Ao0uXLgGdP1tGG5iYmCgLFiyQbdu2ZfRUAOBI9KMAECJDpPzdwlhUVJQJJIYOHSorV66UM2fOyJIlS6R9+/Yya9YsefDBB7NukrcuJ96sWTPp37+//P7771KvXj3Zs2ePKbs4e/Zs6dSpU8CNAQAnoB8FgBDjsDkYKekwqdWrV5sshmbYv//+e4mNjc3QtcjvDIYuBKU1c9X8+fPNBVEjHl1Aavjw4QE3BACcgn4UAEKMK8U8jPRu+p4wvg699NJLJoNRoEABMx/j0KFD8sgjj8iOHTtk165d8vbbb2ddBuPs2bNSqFAh83jRokUmutEVANu1aycDBw4MuCEA4BT0owAQYhyWwWj+V/Wo5557zmTOixcvbun5/c5glClTxqRRdGlxvTC2bt3a7D99+rTkypXL0sYBgB3RjwJAiPE3exFI1akQogvqabWoAQMGyF133SVPPPGEzJ07V06cOGHJ+f3OYGhDevToIdHR0VKuXDkTAblTLbfeeqsljQIAO6MfBQAE06hRo8xPXVhv1apVZv6FrurdvXt3qVKlitxxxx1m+FTnzp2zJsB4/PHHpUGDBrJ//34T8WTL9mcSpGLFiowdBoB0oB8FgBDjsCFSbnqjq23btmZTp06dMou9vv766zJlyhRJSkrKmgBDacUT3XRiom66MJSOHQYApA/9KACEEIcGGMnJybJu3TrPWhjffvutyWro/IwHHngg4PMGtA7Gu+++a9L4uXPnNlvNmjXlvffeC7gRAOA09KMAEEIcNgdjzJgxcs8990jBggWlUaNGMnHiRClSpIhMmDDBVJDS0unTp0/PugBD0yaPPfaYadSHH35otrvvvlv++c9/yvjx4wNuCAA4Bf0oADh3ob1JkyZJ+fLlTVGPhg0bytq1a9M8durUqaasuQYCurVq1SrV8ZoFHzx4sJQsWdLcsNJjtNTs9WggoeVpx44dK7/++qsZsqs3ufr06SMVKlSQjPJ7iJSOyZo8ebL07NnTs69Dhw5So0YNGTJkiDz99NMZbhQA2Bn9KACEmOQAAoYAMhhz5syR+Ph4M79Bgwv9Rb9Nmzayfft2KVasWKrjddiSTry+/fbbTUAyevRoU3lwy5YtUqpUKU82QtdReuedd0xw8OKLL5pzbt26Nc3KhLrmRWbyO4Nx+PBh8yWvpfv0NQDA9dGPAoBzM9h9+/aV3r17S/Xq1U2goesgpbWo3fvvv28Kg9SuXVuqVasm06ZNM/Mmli1b5sleaJDywgsvyH333WeG2+oQXA0gFixYIMHid4BRqVIlk873FZFVrlzZqnYBgG3RjwKAfeZgJCYmem2XLl3y+RGXL1+WDRs2mCFMblpFUJ/r2kjpcfHiRbly5Ypnsdbdu3fLkSNHvM6ZP39+kx1J7zkzg99DpIYOHSrdunUz9dobN25s9umMc42kfF0wAQDe6EcBwD5VpHTx1JQSEhLMcNdr6SJ2Wvb12lWz9fm2bdvS9ZG68nZsbKwnoNDgwn2Oa8/pfi0sAoxOnTqZySWa4nGnXm6++Wazr06dOpnRRgCwFfpRAAgxgVSF+ut4nSAdExPj2R0VFSWZtTje7NmzzbyMtOZWhAq/AgxN+3z//fcmxaOVTooWLZqhD9dJjrppKSylExx1Frx7sQ8AsBv6UQCwVwZDg4uUAUZatAxs9uzZ5ejRo1779XmJEiXkerTakwYYS5cuNfMs3Nzv03NoFamU59R5GyE/B2PTpk1mcomWUmzfvr0ZQ/zVV19l6MNLly5t/rB0PNr69eulRYsWZoKKzowHALuhHwUA55apjYyMlLp163omaCv3hG1diyItWiVq2LBhsmjRIrNAa0paNUqDjJTndN/Iut45UwYiDz30kBl2lSNHDhMApdwyPYOhY770S8ydO9ekZfSL9u/f/4Z1dq9HL7ApjRgxwtyJW7NmjbkLBwB2Qj8KAM4WHx8vcXFxJlBo0KCBqQB14cIFU1VKaflyLT87cuRI81zL0mpWetasWWbtDPe8iujoaLNFRETIgAEDZPjw4aZIiLtMrQYMHTt2vGF7evXqJfv27TPv0QyIns8K6Q4w9O7Y4sWL5bbbbjPPtZyWzmDXKCk9aaEb0UkvH330kflDTivi0ln5KWfm62cDQLigHwUA+83B8Ee3bt3k+PHjJmjQYEGHMWlmwj1JW3/Z18pSbnrDSIfUdu7cOc2J5P/6179Mv//II4/ImTNnpEmTJuac6Zmn8c0338iqVassH06V7gDj1KlTJhXvpqv/5c2bV06ePJmhC+PmzZvNhfCPP/4wkdj8+fNNXWBfNJrT6isAEI7oRwHA2QvtKc1c6+aLTuBOyT2/7no06/DSSy+ZzV9aAUvX0gjqJG9dETBlyStt0C+//CLnzp3z7Es58SQ9qlatasYlnz17Vj7++GOTNlq5cqXPi+OgQYNMainlnbdrS4MBQCijHwWAEJQUwOpw/gYkIUiHaD3//PPyxhtvmCFYVolwpTNs0XSNRki+Dnfv15+aos8Iret70003mS96I3ph1MVEntKSYGJPo51QsTJO7C2f2N7Eh8W2ftf0s4j55T2jw5hCuR+tH0jd8jDxnWuh2N6Se8XWHPBXKF+IbSUmi+T/zZp+1GruPvDsfSIxOf187xWR/J+E5vdKr4IFC5rF+65evWpWFM+ZM2eqzHsg0n090ZUCs4LOpk9rBUQACGf0owAQohycwcgM6Q4wypUrZ/mHa6pea7WXLVvWDA/QGfI69iyjZRsBIBTRjwIAQokOqc0MQc2IHzt2zJTjOnz4sElP6bhjvSjeddddwWwWAIQN+lEACJ8qUqFIh+UuWLDAzAdUWuK8Q4cOWbMORmZ46623gvnxABD26EcBwAIOHSK1c+dOueeee+TgwYOmYIi72qAW//j888/NfL5A+PtHCQAAANhLFqzkHYqefPJJE0Ts379fNm7caDZdi0MX7NPXAmXXoiEAAABA+rgCGPJk/fIRWU5Lmq9Zs8Ys+upWuHBhGTVqlDRu3Djg8/qdwdCVA/fu3RvwBwKA09GPAkCIcWgGIyoqymsdJrfz589LZGRk1gUYn3zyiUmltGzZ0lQroRQiAPiHfhQAEAruvfdeeeSRR+T77783azHpphmNf/7zn2aid5YFGLpa7Lp168wM86eeekpKlCghjz32mNkHALgx+lEACDEOzWC89tpr5oZXo0aNJFeuXGbToVGVKlWSV199NeDzBjTJu06dOqZBhw4dMhVMDhw4YBqj5RG1MbqiIQAgbfSjABCCZWr93cJcgQIFTFZ9+/bt8vHHH5tNH8+fP9+UPg9UhqpIaRrlypUrcvnyZfNYlxufOHGiKW01Z86cjJwaAByBfhQAQoBDMxhulStXlvbt25tNsxcZFVAVqQ0bNsj06dPlgw8+MJNDdJGnSZMmeRr0+uuvm9JW3bp1y3ADAcCO6EcBIIQ4aKG9+Ph4GTZsmOTNm9c8vp5x48ZlTYBx6623yrZt26R169Ymra+RzrUr/XXv3t2MKwYApEY/CgAhRrMREQG8Jwz98MMPJnPufpwZ/A4wunbtKn369JFSpUqleUyRIkUkOTlMwzoAyGT0owCAYFm+fLnPx1byaw6GRjszZsyQxMTETGkMANgd/SgAhKDkAOZf2OAeUJ8+fXyug3HhwgXzWpYEGDlz5pQ//vgj4A8DAKejHwWAEOTQKlLvvPOO/P7776n26753330366pI9evXT0aPHi1Xr14N+EMBwMnoRwEgxDisilRiYqIph67VCzWDoc/d2+nTp+WLL76QYsWKZd0cDF0IatmyZbJ48WIzUVFnoKc0b968gBsDAE5APwoAISaQYCEpvNe/iIiIMFuVKlVSva77hw4dmnUBhjaoU6dOAX8gADgd/SgAhJjkAKpIhfEQqeXLl5vsRYsWLWTu3LlSqFAhz2uRkZFSrlw5iY2NzboAQ+u2AwACRz8KAAimO+64w/zcvXu3Wdg1W7YMrb1tzUJ7Om54xYoVsmvXLvn73/8u+fLlk0OHDklMTIxER0db2kAAsCP6UQAIIQ4bIuWmmYozZ87I2rVr5dixY6nKo+sisFkSYOzdu1fuvvtu2bdvn1y6dEnuuusuc2HUCYv6fMqUKQE1BACcgn4UAEKMw4ZIuX322WfSo0cPOX/+vLnBpXMv3PRxoAGG3/kQXVm2Xr16ZoZ57ty5Pfvvv/9+M2kRAHB99KMAEGIcug7GM888Y9a70ABDMxl6XXJvp06dCvi8fmcwVq1aJd99952ZAJJS+fLl5eDBgwE3BACcgn4UAEKMBgwuP99jgwDj4MGD8uSTT0qePHksPa/fGQwdm5WUlHrQ2YEDB0yKHwBwffSjABBiHLrQXps2bWT9+vWWn9fvDEbr1q1lwoQJ8uabb3rGZ2laJSEhQe655x4JhjcDGDYXLpJ+ENsbe0XsbfOLYnf9Nw4Tu0q8LPKvqdaeMxT70dK6yrjY1RyxvWlib4+J/dk5eanX+d+C3Qj40q5dOxk4cKBs3brVrMuUM6f3laBDhw6SJQHGK6+8YqKd6tWryx9//GGqn+zYsUOKFCkiH3zwQUCNAAAnoR8FgBDj0CFSffv2NT9feumlVK/pzS9f2fZMCTBKly4tP/74o8yePVt++uknc9ft4YcfNjPQU05WBAD4Rj8KACHGoQFG8jVlaYO6DkaOHDnkf/7nf6xvDQA4BP0oAISQQH7PtkGAkZJm1HPlyiVBCTDefffd674eaL1cAHAK+lEACDHJAWQw/D0+BOkQqJdfftmsv3T06FH59ddfpWLFivLiiy+ayoaaXc+SAEPrt6d05coVuXjxoim3qCWuuDACwPXRjwIAQsGIESPknXfekTFjxnjmY6hbbrnFFCMJNMDwu0xtygU4dNOxw9u3b5cmTZowOREA0oF+FABCjEPL1L777rumoqHOAcyePbtnf61atWTbtm0Bn9fvAMOXypUry6hRo1LdlQMApA/9KAAEUVKAmw0W2qtUqZLPyd+aXQ9qgOGesHjo0CGrTgcAjkM/CgBB4tAAo3r16rJq1apU+z/++GOpU6dOwOf1ew7Gp59+6vXc5XLJ4cOHZeLEidK4ceOAGwIATkE/CgAhJjmAVZsDnOQ9adIk+fe//y1HjhwxQ5Fef/11adCggc9jt2zZIoMHD5YNGzbI3r17Zfz48TJgwACvY86dO2cmZc+fP1+OHTtmAoNXX31V6tevf8O26Lnj4uJMJkOzFvPmzTNDdnXo1MKFC7MuwOjYsWOqRTiKFi0qLVq0MItHAQCuj34UAEJMUtYEGHPmzJH4+HhTtalhw4ZmIrUuvKq/1BcrVizV8VoARKs6denSRZ5++mmf5/zHP/4hP//8s7z33nsSGxsrM2fOlFatWpnVuUuVKnXd9tx3333y2WefmYX28ubNawKO2267zey76667JMsCjMxakAMAnIJ+FACcady4caZaU+/evc1zDTQ+//xzefvtt+X5559PdbxmIdyZCF+v//777zJ37lz55JNPpFmzZmbfkCFDTIAwefJkGT58+A3b1LRpU1myZIlYKeA5GCdOnJDExERLGwMATkI/CgDhPwdD+/GU26VLl3x+xOXLl81QJ80uuGXLls08X716dUDNvnr1qlnL4toF8nLnzi3ffPPNDd+v2ZGTJ0+m2n/mzBnzWpYEGPph/fr1kyJFikjx4sWlYMGCUqJECRk0aJBJ4QAAro9+FABCkCuAErV/DZEqU6aM5M+f37ONHDkyzZtKGgxo35+SPtf5GIHIly+fNGrUSIYNG2aKhOj5dYiUBiw6t+9G9uzZY95zLQ2SdF5Gpg+ROnXqlPkC+mFaK/fmm282+3V8l05O0dSKRko//fSTrFmzRp588smAGwUAdkQ/CgChKZCiUO7j9+/fLzExMZ79UVFRkpV07kWfPn3MfAtdy0LnUHTv3t1kS9JTbOSrr74ygZGbBhzLli0zK3lneoChkz90ldldu3alirz0tdatW8tDDz0kixcvltdeey3gBgGAXdGPAoD9AgwNLlIGGGnRzLUGAEePHvXar881kx2om266SVauXCkXLlwwQ7RKliwp3bp1u+4Qp5TFRrSKVEo5c+Y0wUVGio6ke4jUggULZOzYsakuikr/UHSJcZ1kojPjr20oAIB+FACcvJB3ZGSk1K1b12QHPJ+bnGyea3Y7o7QKlAYXp0+fNlkJrRCVFv1c3cqVK2dK27qf66bDo7Sq1b333pv5GQwdx1WjRo00X7/lllvMRJWEhISAGwMAdkY/CgDOFv/XDaR69eqZtS+0TK1mHtxVpXr27GmGOrnncejEcB1G636sQ2w3bdok0dHRnhW4NZjQ9ZSqVq0qO3fulIEDB0q1atU857yeoUOHmnkc19LPmj17tmlPpmYwNK2jE0HSsnv3bp/1ewEAf6IfBQBnL+TdrVs3k8nW9SZq165tgoVFixZ5Mtv79u3zmpytE7d14TzddL++Vx/r2hduZ8+eNcVDNKjQgKBJkyYm6NChTjeiQYi+/1q6eF96ApQMZzB0EZD/9//+n5mEqCmelDSVoisI3n333QE3BADsjn4UAEJTIEOeAl3RqH///mbzZcWKFV7PdS6EZieup2vXrmYLhJ5bF3u91oEDB7wmfmfqJG9N51SuXNkTJWmjfvnlF/nPf/5jLo66rDgAwDf6UQCw3yTvcFSnTh0TWOjWsmVLyZEjh1cVKc2oZ+SGV7oDjNKlS5uauo8//rip1+6OprRhupT4xIkTpWzZsgE3BADsjn4UAEJTcgABQ6AZjFDgriKlQ7Q0u65zOtw0w66Zk06dOmV+gKEqVKggX375pZmdvmPHDrNPJ5gUKlQo4AYAgJPQjwKAs4dIhQJ3MRENJHReyLUrgauff/7ZFB/J9ADDTVee1ZnvAIDA0I8CAILt2pLoOrn7gw8+kGnTppmF+nyt8m1pFanMNmrUKDNMYMCAAcFuCgCELfpSAAjdKlKh6uuvvzbBhq6joZWqWrRoIWvWrAn4fAFlMKy2bt06eeONN6RmzZrBbgoAhC36UgAIjNMmeasjR47IjBkz5K233jIrgGslKi02oovCVq9eXTIi6BmM8+fPS48ePWTq1KlmyAAAwH/0pQAQ2it5h5L27dubhfl++ukns9ifrrfx+uuvW3b+oAcYWqqxXbt20qpVqxseq1GVRlgpNwBA+vtS+lEASM1pQ6S+/PJLefjhh81K3nrtyJ49u6XnD2qAoUuQb9y40bMc+o3ocbroh3srU6ZMprcRAEKdP30p/SgApOa0DMY333xjJnTXrVtXGjZsaMqknzhxIvwDjP3798tTTz0l77//vs/SWL5o3Xhdzty96TkAwMn87UvpRwEAf/vb38yQ2sOHD8ujjz5qblTFxsZKcnKyLFmyxAQfYRlgaOmrY8eOyW233WZWD9Rt5cqV8tprr5nHvspiRUVFSUxMjNcGAE7mb19KPwoAaS+0588WzhkMt7x580qfPn1MRmPz5s3yzDPPmGqExYoVkw4dOkjYBRi6LLl+EV1B0L3Vq1fPTFLUx1aPBQMAO6IvBYCMc9ocDF900veYMWPkwIEDZi2MjAhamdp8+fKlWh1Qo6jChQsHvGogADgNfSkAZJzTVvK+Hr0x1bFjR7OF9ToYAAAAQLA4cR2MzBRSAcaKFSuC3QQACHv0pQDgHwIMawV9HQwAAAAA9hFSGQwAAAAgqzEHw1oEGAAAAHA0hkhZiwADAAAAjuYKICOh74FvBBgAAABwNDIY1iLAAAAAgKMRYFiLKlIAAAAALEMGAwAAAI5GFSlrEWAAAADA0RgiZS0CDAAAADgaAYa1CDAAAADgaAyRshYBBgAAABwtOYCMBAFG2qgiBQAAAMAyZDAAAADgaAyRshYBBgAAAByNSd7WIsAAAACAoxFgWIsAAwAAAI7GEClrEWAAAADA0chgWIsqUgAAAAAsQwYDAAAAjkYGw1oEGAAAAHA0VwBzKvQ9sHGA0VNEosSeVor9vfCz2NrwZcPE9iZuFttKPC8ytZHY3Wm7XBB8KiG2l0/s7aTYXy6xr+wS8rIygzFp0iT597//LUeOHJFatWrJ66+/Lg0aNPB57JYtW2Tw4MGyYcMG2bt3r4wfP14GDBjg3Y6kJBkyZIjMnDnTnDM2NlZ69eolL7zwgkREREgwMAcDAAAAjpYc4OavOXPmSHx8vCQkJMjGjRtNgNGmTRs5duyYz+MvXrwoFStWlFGjRkmJEr5vlowePVomT54sEydOlF9++cU8HzNmjAlcgoUAAwAAAI6WFODmr3Hjxknfvn2ld+/eUr16dZkyZYrkyZNH3n77bZ/H169f32Q7HnzwQYmK8j1e57vvvpP77rtP2rVrJ+XLl5fOnTtL69atZe3atRIsBBgAAABAgBITE722S5cu+Tzu8uXLZqhTq1atPPuyZctmnq9evTrgz7/99ttl2bJl8uuvv5rnP/74o3zzzTfStm1bCRb7DrkFAAAAMnkORpkyZbz2JyQkmDkR1zpx4oSZL1G8eHGv/fp827ZtEqjnn3/eBDbVqlWT7Nmzm88YMWKE9OjRQ4KFAAMAAACOlpGVvPfv3y8xMTGe/VFpDGXKLB9++KG8//77MmvWLKlRo4Zs2rTJTATXyd5xcXESDAQYAAAAcLSMZDA0uEgZYKSlSJEiJsNw9OhRr/36PK0J3OkxcOBAk8XQeRrq1ltvNRWnRo4cGbQAgzkYAAAAcLTkACZ4+5vxiIyMlLp165r5Ep7PTU42zxs1Crwculaa0rkcKWkgo+cOFjIYAAAAcLSMDJHyR3x8vMkq1KtXz6x9MWHCBLlw4YKpKqV69uwppUqVMtkH98TwrVu3eh4fPHjQDIGKjo6WSpUqmf3t27c3cy7Kli1rhkj98MMPplpVnz59JFgIMAAAAIAs0K1bNzl+/LhZPE8Xxatdu7YsWrTIM/F73759XtmIQ4cOSZ06dTzPx44da7Y77rhDVqxYYfbpehcvvviiPP7442Y9DZ178eijj5rPCBYCDAAAADhaVq7k3b9/f7P54g4a3HRdC5fLdd3z5cuXz2RCdAsVBBgAAABwtKwaIuUUBBgAAABwtKzMYDgBAQYAAAAcjQDDWgQYAAAAcDSGSFmLdTAAAAAAWIYMBgAAABzNvdCev++BbwQYAAAAcDTmYFiLAAMAAACOxhwMaxFgAAAAwNHIYFiLAAMAAACORgbDWlSRAgAAAGAZMhgAAABwNIZIWYsAAwAAAI5GgGGjIVJDhgyRiIgIr61atWrBbBIAhBX6UQDIOFeKeRjp3fQ9CNEMRo0aNWTp0qWe5zlyBL1JABBW6EcBIGPIYFgr6FchvRCWKFEi2M0AgLBFPwoACCVBryK1Y8cOiY2NlYoVK0qPHj1k3759wW4SAIQV+lEAsCaD4e+GEMxgNGzYUGbMmCFVq1aVw4cPy9ChQ6Vp06by888/S758+VIdf+nSJbO5JSYmZnGLASC00I8CQMaxDoaNAoy2bdt6HtesWdNcKMuVKycffvihPPzww6mOHzlypLl4AgD+RD8KABnHHAybDZFKqUCBAlKlShXZuXOnz9cHDRokZ8+e9Wz79+/P8jYCQCijHwUA//lbQSqQjIeThFSAcf78edm1a5eULFnS5+tRUVESExPjtQEA/ot+FAD8xxwMGwUYzz77rKxcuVL27Nkj3333ndx///2SPXt26d69ezCbBQBhg34UABBqgjoH48CBA+YiePLkSSlatKg0adJE1qxZYx4DAG6MfhQAMi45gIwEQ6RCNMCYPXt2MD8eAMIe/SgAZBxVpGy20B4AAAAQTEkBzBtgDkbaCDAAAADgaAQY1iLAAAAAgKMxRMrGZWoBAAAAhDcyGAAAAHA0hkhZiwADAAAAjsYQKWsRYAAAAMDRWAfDWgQYAAAAcDQNLiICeA98I8AAAACAozFEylpUkQIAAABgGTIYAAAAcDSGSFmLDAYAAAAcLSnALRCTJk2S8uXLS65cuaRhw4aydu3aNI/dsmWLdOrUyRwfEREhEyZMSHWM+7Vrt379+kmwEGAAAADA0ZID3Pw1Z84ciY+Pl4SEBNm4caPUqlVL2rRpI8eOHfN5/MWLF6VixYoyatQoKVGihM9j1q1bJ4cPH/ZsS5YsMfu7dOkiwUKAAQAAAEfLqgzGuHHjpG/fvtK7d2+pXr26TJkyRfLkySNvv/22z+Pr168v//73v+XBBx+UqKgon8cULVrUBB/ubeHChXLTTTfJHXfcIcFCgAEAAABHcwWQvdD3qMTERK/t0qVLPj/j8uXLsmHDBmnVqpVnX7Zs2czz1atXW/I99DNmzpwpffr0McOkgoUAAwAAAAhQmTJlJH/+/J5t5MiRPo87ceKEJCUlSfHixb326/MjR45Y0pYFCxbImTNnpFevXhJMVJECAACAoyVl4D379++XmJgYz/6oNIYyZYW33npL2rZtK7GxsRJMBBgAAABwtIwEGBpcpAww0lKkSBHJnj27HD161Gu/Pk9rArc/9u7dK0uXLpV58+ZJsDFECgAAAI6WFVWkIiMjpW7durJs2bL/fm5ysnneqFGjDH+H6dOnS7FixaRdu3YSbGQwAAAA4GgZyWD4Iz4+XuLi4qRevXrSoEEDs67FhQsXTFUp1bNnTylVqpRnHodO2t66davn8cGDB2XTpk0SHR0tlSpV8gpUNMDQc+fIEfxf74PfAgAAAMABAUa3bt3k+PHjMnjwYDOxu3bt2rJo0SLPxO99+/aZylJuhw4dkjp16niejx071mxagnbFihWe/To0St+r1aNCQVgHGC7XnwXCLot9OWEZet/F3Owj8YLYX+J5savEv/4C3f2N3bi/11Wxr8REu/cyNr8Qqotif1fEthL/+m527Uf91b9/f7P5kjJocK/SnZ4/t9atW4fUn2+EK5Ra46cDBw6Y0mAAkNm0Skjp0qXFbuhHATi5H9V1K7S0bEURyR7ATeDfROTs2bPpmuTtJGGdwdASXPqPNV++fFmymIj+I9QL8bXlyOzE7t+R7xf+svo76j2Yc+fOBb3kn136USf8O+X7hT+7f0f60dSSs+g9ThHWAYaOUQtGJJzecmThzO7fke8X/rLyO+rdLbsKVj/qhH+nfL/wZ/fvSD/6XwQY1grrAAMAAADIKB3u5O+cAQKMtBFgAAAAwNEIMKzFQnt+0KXfExISgroEfGaz+3fk+4U/J3xHu7P73yHfL/zZ/Tva/fsh+MK6ihQAAACQ0SpSxQK4664ZjGNUkfKJIVIAAABwNIZIWYsAAwAAAI6WHECAwRCgtBFgAAAAQJweYPi7EhABRtoIMAAAACBOHyJFgGEdqkilw9dffy3t27c3K1DqSrcLFiwQOxk5cqTUr1/frORbrFgx6dixo2zfvl3sZPLkyVKzZk3PokKNGjWSL7/8Uuxq1KhR5t/qgAEDxA6GDBlivk/KrVq1asFuFvxEXxre6EfDH30psgoBRjpcuHBBatWqJZMmTRI7WrlypfTr10/WrFkjS5YskStXrkjr1q3N97YLXalYLxYbNmyQ9evXS4sWLeS+++6TLVu2iN2sW7dO3njjDfOLgJ3UqFFDDh8+7Nm++eabYDcJfqIvDW/0o/ZAX5p2BiOQDb4xRCod2rZtaza7WrRokdfzGTNmmLtvehFp1qyZ2IHeNU1pxIgR5m6c/iKgna1dnD9/Xnr06CFTp06V4cOHi53kyJFDSpQoEexmIAPoS8Mb/ag90Jd6i4yMNH8eR44cCej9+l49B7yRwUAqWs9ZFSpUSOwoKSlJZs+ebe4qaorfTvTuabt27aRVq1ZiNzt27DBDaypWrGgu/vv27Qt2kwDH9qX0o+GLvtRbrly5ZPfu3eb/10A2fa+eA97IYMBLcnKyGW/auHFjueWWW8RONm/ebC6Ef/zxh0RHR8v8+fOlevXqYhd6sd+4caNJ7dtNw4YNzd3gqlWrmpT+0KFDpWnTpvLzzz+b8e5AqLFrX0o/Gt7oS33TAIEgwVoEGEh150Y7GjuOydQOddOmTeaOw8cffyxxcXFmzLQdLo779++Xp556yoz7tmMnmXJYjY6J1otkuXLl5MMPP5SHH344qG0DnNSX0o+GN/pSZBUCDHj0799fFi5caCq96GQ+u9ExkpUqVTKP69ata+5Qvfrqq2YiX7jTMd7Hjh2T2267zWsIg/5dTpw4US5duiTZs2cXuyhQoIBUqVJFdu7cGeymAI7qS+lH7dOPKvpSZBYCDIjL5ZInnnjCpLpXrFghFSpUEKcMYdALhh20bNnSDF1IqXfv3qb84HPPPWe7i6JOwty1a5c89NBDwW4K4Oi+lH40vNGXIrMQYKTzf8CU0b1O6NEUsU7cK1u2rNghlT9r1iz55JNPzBhMdyWF/PnzS+7cucUOBg0aZFLD+vd17tw58331F4CvvvpK7ED/3q4d5503b14pXLiwLcZ/P/vss6aCjabyDx06JAkJCeZi371792A3DX6gLw1v9KPhj74UWYUAIx203vedd97peR4fH29+6thTnSwV7rTMoGrevLnX/unTp0uvXr3EDjTt3bNnTzOpTS/2OvZUL4p33XVXsJuGdDhw4IC5AJ48eVKKFi0qTZo0MaUx9THCB31peKMfDX/0pcgqES7N6QIAAACABVgHAwAAAIBlCDAAAAAAWIYAAwAAAIBlCDAAAAAAWIYAAwAAAIBlCDAAAAAAWIYAAwAAAIBlCDCAGyhfvrxMmDDhuscMGTJEateunWVtAoBwQ18KOAcBBiylq9V27NjRa9/HH38suXLlkldeeSVTPnPFihUSERHh2YoXLy6dOnWS3377zZLzr1u3Th555BHPc/2MBQsWeB3z7LPPyrJlyyz5PACgLwUQzggwkKmmTZsmPXr0kMmTJ8szzzyTqZ+1fft2OXTokHz00UeyZcsWad++vSQlJWX4vEWLFpU8efJc95jo6GgpXLhwhj8LAHyhLwUQTggwkGnGjBkjTzzxhMyePVt69+7t2f/JJ5/IbbfdZu7EVaxYUYYOHSpXr141r/Xp00fuvfder/NcuXJFihUrJm+99dZ1P0+PKVmypDRr1kwGDx4sW7dulZ07d5rX9KJ80003SWRkpFStWlXee+89z/tcLpdJy5ctW1aioqIkNjZWnnzySZ9pfX2s7r//fnP3zf382rR+cnKyvPTSS1K6dGlzTn1t0aJFntf37Nlj3j9v3jy58847zUW3Vq1asnr16gD/tAHYFX0pfSkQdlyAheLi4lz33Xef61//+pcrOjratXTpUq/Xv/76a1dMTIxrxowZrl27drkWL17sKl++vGvIkCHm9W+//daVPXt216FDhzzvmTdvnitv3ryuc+fO+fzM5cuXu/Sf8unTp73eo/t++ukn8zhnzpyuSZMmubZv3+565ZVXzGf83//9nzn2o48+Mm364osvXHv37nV9//33rjfffNNzrnLlyrnGjx9vHh87dsycd/r06a7Dhw+b5yohIcFVq1Ytz3vGjRtnzvnBBx+4tm3bZv48tA2//vqreX337t3mPNWqVXMtXLjQtKtz587ms65cuWLJ3wWA8EVf+if6UiA8EWDA8otiZGSk6fCXLVuW6vWWLVu6Xn75Za997733nqtkyZKe59WrV3eNHj3a87x9+/auXr16pfmZ114U9YJ6++23u0qVKuW6dOmSedy3b1+v93Tp0sV1zz33mMd6kaxSpYrr8uXLPs+f8qKo9LPmz5/vdcy1F8XY2FjXiBEjvI6pX7++6/HHH/e6KE6bNs3z+pYtW8y+X375Jc3vCsAZ6Ev/RF8KhCeGSMFyNWvWNOnuhIQEOX/+vNdrP/74o0l36zhb99a3b185fPiwXLx40Rzzj3/8Q6ZPn24eHz16VL788kuT7r8RTaHnzZvXpOUvXLggc+fONWn8X375RRo3bux1rD7X/apLly7y+++/myEG2pb58+d7hhkEIjEx0Yxfvt5npvyzctMhCerYsWMBfzYA+6AvpS8FwhUBBixXqlQpU43k4MGDcvfdd8u5c+c8r+lFUscJb9q0ybNt3rxZduzYYcYRq549e5qqJTqGdubMmVKhQgVp2rTpDT931apV8tNPP5mLkp63YcOG6WpvmTJlzKTG//znP5I7d255/PHHzdhjHa+c2XLmzOl5rOOI3WOOAYC+NP3oS4HQQoCBTFGuXDlZuXKlHDlyxOvCqBMS9QJUqVKlVFu2bH/+c9QKIlqeUe+8zZgxw2tS4/XoxVMnH+bLl89r/8033yzffvut1z59Xr16dc9zvRhqpZTXXnvNXND1gqwX67QuZNerqBITE2Pu/N3oMwHgRuhL6UuBcJQj2A2AfendLL3AaGWPNm3amMofWpFEK5tolZHOnTubC6Gm+n/++WcZPny4572a2tfj9OITFxeXoXYMHDhQunbtKnXq1JFWrVrJZ599ZiqOLF261LyuF179HL1LpxVI9E6fXiT1wu6LDlnQOu2apteqJgULFvT5mTqsQS/SWvVEL/B6J/D999/P0HcB4Dz0pfSlQLghg4FMpWN59cJ44sQJc2Fs1KiRLFy4UBYvXiz169eXv/3tbzJ+/PhUFyC9eOk4Wn2P3sHKCL2D9+qrr8rYsWOlRo0a8sYbb5iLVPPmzc3rBQoUkKlTp5qLnI7j1YulXjjTqsWui1wtWbLEXPT1QuuLlmaMj4839epvvfVW8wvBp59+KpUrV87QdwHgTPSl9KVAOInQmd7BbgRwLR1frOOP9eL1wAMPBLs5ABCW6EsBBANDpBBSdFKe3qHTO1t6N6xDhw7BbhIAhB36UgDBRICBkLJv3z4zwVCHA+h43hw5+CcKAP6iLwUQTAyRAgAAAGAZJnkDAAAAsAwBBgAAAADLEGAAAAAAsAwBBgAAAADLEGAAAAAAsAwBBgAAAADLEGAAAAAAsAwBBgAAAADLEGAAAAAAEKv8f1BjBiIYI694AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test input\n",
    "test_X = np.array([[1, 2, 3, 4, 5]])\n",
    "test_emb = get_embeddings(test_X, vocab_size, d_model) + positional_encoding(seq_length, d_model)\n",
    "\n",
    "# Get attention weights\n",
    "_, attn_weights = multi_head_attention(test_emb, n_heads, d_model)\n",
    "print(\"Attention weights shape:\", attn_weights.shape)\n",
    "\n",
    "# Plot heatmaps for each head\n",
    "fig, axes = plt.subplots(1, n_heads, figsize=(10, 4))\n",
    "for head in range(n_heads):\n",
    "    # Extract weights for batch=0, head= head\n",
    "    weights = attn_weights[0, head]  # Shape: (seq_length, seq_length)\n",
    "    ax = axes[head]\n",
    "    im = ax.imshow(weights, cmap='hot', interpolation='nearest')\n",
    "    ax.set_title(f'Head {head+1}')\n",
    "    ax.set_xlabel('Key Position')\n",
    "    ax.set_ylabel('Query Position')\n",
    "    ax.set_xticks(np.arange(seq_length))\n",
    "    ax.set_yticks(np.arange(seq_length))\n",
    "    ax.set_xticklabels(np.arange(1, seq_length+1))\n",
    "    ax.set_yticklabels(np.arange(1, seq_length+1))\n",
    "fig.colorbar(im, ax=axes, label='Attention Weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53168254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed-forward output shape: (1, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "def feed_forward(X, d_model, d_ff):\n",
    "    \"\"\"Apply point-wise feed-forward network.\"\"\"\n",
    "    W1 = np.random.randn(d_model, d_ff) * 0.1\n",
    "    b1 = np.zeros(d_ff)\n",
    "    W2 = np.random.randn(d_ff, d_model) * 0.1\n",
    "    b2 = np.zeros(d_model)\n",
    "    # Linear -> ReLU -> Linear\n",
    "    hidden = np.maximum(0, np.matmul(X, W1) + b1)\n",
    "    output = np.matmul(hidden, W2) + b2\n",
    "    return output\n",
    "\n",
    "# Test feed-forward\n",
    "ff_output = feed_forward(mha_output, d_model, d_ff)\n",
    "print(\"Feed-forward output shape:\", ff_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9478f",
   "metadata": {},
   "source": [
    "The feed-forward layer applies a two-layer neural network (linear → ReLU → linear) to each token independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de328510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (1, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "def encoder_layer(X, n_heads, d_model, d_ff):\n",
    "    \"\"\"Combine multi-head attention and feed-forward with residual connections.\"\"\"\n",
    "    attn_out, _ = multi_head_attention(X, n_heads, d_model)  # Ignore weights\n",
    "    X = X + attn_out  # Residual connection\n",
    "    ff_out = feed_forward(X, d_model, d_ff)\n",
    "    X = X + ff_out  # Residual connection\n",
    "    return X\n",
    "\n",
    "# Test encoder\n",
    "enc_output = encoder_layer(X_emb_with_pos, n_heads, d_model, d_ff)\n",
    "print(\"Encoder output shape:\", enc_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe94210",
   "metadata": {},
   "source": [
    "The encoder layer combines multi-head attention and feed-forward with residual connections (adding input to output) for better training stability. The output shape remains `(1, 5, 8)` due to residual connections preserving dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1d71967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (1, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "def decoder_layer(X, enc_output, n_heads, d_model, d_ff):\n",
    "    \"\"\"Simplified decoder with attention over encoder output.\"\"\"\n",
    "    attn_out, _ = multi_head_attention(X, n_heads, d_model)  # Ignore weights\n",
    "    X = X + attn_out\n",
    "    # Cross-attention with encoder output\n",
    "    Q = X\n",
    "    K = V = enc_output\n",
    "    cross_attn_out, _ = multi_head_attention(Q, n_heads, d_model)  # Ignore weights\n",
    "    X = X + cross_attn_out\n",
    "    ff_out = feed_forward(X, d_model, d_ff)\n",
    "    X = X + ff_out\n",
    "    return X\n",
    "\n",
    "# Test decoder\n",
    "dec_input = get_embeddings(y[:1], vocab_size, d_model) + pos_enc\n",
    "dec_output = decoder_layer(dec_input, enc_output, n_heads, d_model, d_ff)\n",
    "print(\"Decoder output shape:\", dec_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d49cca",
   "metadata": {},
   "source": [
    "The decoder performs:  \n",
    "- Self-attention on the target sequence (`X`).\n",
    "- Cross-attention with the encoder's output (`enc_output`).\n",
    "- Feed-forward processing.\n",
    "\n",
    "Residual connections preserve the shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8173cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output probabilities shape: (1, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "def transformer(X, y, vocab_size, d_model, n_heads, d_ff):\n",
    "    \"\"\"Combine encoder and decoder.\"\"\"\n",
    "    # Encoder\n",
    "    X_emb = get_embeddings(X, vocab_size, d_model)\n",
    "    X_emb += positional_encoding(X.shape[1], d_model)\n",
    "    enc_output = encoder_layer(X_emb, n_heads, d_model, d_ff)\n",
    "    \n",
    "    # Decoder\n",
    "    y_emb = get_embeddings(y, vocab_size, d_model)\n",
    "    y_emb += positional_encoding(y.shape[1], d_model)\n",
    "    dec_output = decoder_layer(y_emb, enc_output, n_heads, d_model, d_ff)\n",
    "    \n",
    "    # Output projection\n",
    "    W_out = np.random.randn(d_model, vocab_size) * 0.1\n",
    "    logits = np.matmul(dec_output, W_out)\n",
    "    probs = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)  # Softmax\n",
    "    return probs\n",
    "\n",
    "# Test Transformer\n",
    "probs = transformer(X[:1], y[:1], vocab_size, d_model, n_heads, d_ff)\n",
    "print(\"Output probabilities shape:\", probs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f8a80",
   "metadata": {},
   "source": [
    "Combines encoder and decoder to form the full Transformer.  \n",
    "\n",
    "Output shape is `(batch_size, seq_length, vocab_size)` (e.g., `(1, 5, 10)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4365b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3293\n",
      "Epoch 2, Loss: 2.3568\n",
      "Epoch 3, Loss: 2.3111\n",
      "Epoch 4, Loss: 2.3005\n",
      "Epoch 5, Loss: 2.3364\n",
      "Epoch 6, Loss: 2.2977\n",
      "Epoch 7, Loss: 2.3306\n",
      "Epoch 8, Loss: 2.2973\n",
      "Epoch 9, Loss: 2.3372\n",
      "Epoch 10, Loss: 2.3245\n"
     ]
    }
   ],
   "source": [
    "def train_transformer(X, y, epochs=10):\n",
    "    \"\"\"Train the model with a simple loss function.\"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        probs = transformer(X, y, vocab_size, d_model, n_heads, d_ff)\n",
    "        # Cross-entropy loss (simplified)\n",
    "        loss = -np.mean(np.log(probs[np.arange(y.shape[0])[:, np.newaxis], np.arange(y.shape[1]), y] + 1e-10))\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Train\n",
    "train_transformer(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eb786f",
   "metadata": {},
   "source": [
    "Computes forward pass through the Transformer and calculates a simplified cross-entropy loss. No backpropagation (for simplicity); uses random weights. Prints loss for 10 epochs. Expect random losses due to untrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b44da49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[1 2 3 4 5]]\n",
      "Predicted output: [[7 5 5 5 7]]\n",
      "Output shape: (1, 5)\n"
     ]
    }
   ],
   "source": [
    "def predict(X):\n",
    "    \"\"\"Predict reversed sequence.\"\"\"\n",
    "    y_dummy = np.zeros((X.shape[0], seq_length), dtype=np.int32)  # Dummy target with integer type\n",
    "    probs = transformer(X, y_dummy, vocab_size, d_model, n_heads, d_ff)\n",
    "    return np.argmax(probs, axis=-1)\n",
    "\n",
    "# Test prediction\n",
    "test_X = np.array([[1, 2, 3, 4, 5]])\n",
    "print(\"Input:\", test_X)\n",
    "print(\"Predicted output:\", predict(test_X))\n",
    "print(\"Output shape:\", predict(test_X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165cb42d",
   "metadata": {},
   "source": [
    "The predicted output `[[1 6 3 3 9]]` for the input `[[1 2 3 4 5]]` is expected to be random since the model uses random weights without training, but the correct output shape `(1, 5)` confirms the pipeline works as intended."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
