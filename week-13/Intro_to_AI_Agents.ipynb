{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dccc1cf",
   "metadata": {},
   "source": [
    "# Introduction to Agents  \n",
    "\n",
    "An **AI Agent** is an autonomous computational entity that perceives its environment through sensors, processes information, makes decisions, and takes actions to achieve specific goals. Unlike traditional software programs that follow predetermined instructions, AI agents exhibit intelligent behavior by adapting their actions based on environmental feedback and learning from experience.  \n",
    "\n",
    "**Why AI Agents Matter**  \n",
    "\n",
    "AI agents represent a fundamental shift from passive software tools to active, autonomous systems. They are crucial for several reasons:  \n",
    "\n",
    "**Autonomy and Efficiency**: Agents can operate independently, making decisions without constant human supervision. This enables automation of complex tasks that would be impractical for humans to monitor continuously.  \n",
    "\n",
    "**Adaptability**: Unlike rigid rule-based systems, agents can learn and adapt to changing environments, making them suitable for dynamic, unpredictable systems.  \n",
    "\n",
    "**Scalability**: A single agent architecture can be replicated and deployed across multiple environments, from managing smart homes to controlling autonomous vehicles.  \n",
    "\n",
    "**Problem-Solving Capability**: Agents can tackle complex problems by breaking them down into smaller tasks and coordinating multiple actions over time.  \n",
    "\n",
    "\n",
    "### Real-World Context  \n",
    "\n",
    "AI agents are already transforming numerous industries:  \n",
    "\n",
    "- Autonomous Vehicles → Automotive and Transportation Industry\n",
    "- Virtual Assistants → Consumer Electronics and Software Services Industry\n",
    "- Trading Systems → Financial Services Industry\n",
    "- Game AI → Gaming and Entertainment Industry\n",
    "- Robotics → Manufacturing and Industrial Automation Industry\n",
    "\n",
    "**Cross-Industry Impact**: AI agents also create ripple effects in **Healthcare** (diagnostic tools, robotic surgery), **Retail** (personalized marketing, inventory management), and **Energy** (smart grids, predictive maintenance), as these industries adopt AI technologies from the above sectors.  \n",
    "\n",
    "**Data and AI Infrastructure**: The growth of AI agents relies on the Cloud Computing and Data Analytics Industry, which provides the computational power and data processing capabilities needed for training and deploying AI models across all these sectors.  \n",
    "\n",
    "**Core Industries**  \n",
    "- Food and Agriculture\n",
    "- Water Supply and Sanitation  \n",
    "- Energy and Utilities\n",
    "- Healthcare and Pharmaceuticals\n",
    "- Transportation and Logistics\n",
    "- Housing and Construction\n",
    "- Security and Defense  \n",
    "\n",
    "\n",
    "| Industry                              | AI Adoption Rate (2025) | Key Notes/Source                                                                                           |\n",
    "|----------------------------------------|------------------------|------------------------------------------------------------------------------------------------------------|\n",
    "| Automotive/Transportation              | 70%                   | Highest in logistics and autonomous systems; lowest in some sub-sectors per procurement surveys (PRNewswire/Zebracat average). |\n",
    "| Consumer Electronics/Software Services | 72%                   | Driven by virtual assistants and app development; aligns with tech sector (Zebracat).                      |\n",
    "| Financial Services                     | 65%                   | Algorithmic trading and fraud detection lead; hedge funds at 68% (Zebracat/Netguru).                       |\n",
    "| Gaming/Entertainment                   | 60%                   | Procedural generation and recommendations (e.g., Netflix/Spotify); estimated from media trends (Coherent Solutions/ DemandSage). |\n",
    "| Manufacturing/Industrial Automation    | 77%                   | Robotics and predictive maintenance; up from 70% in 2024 (Netguru/Mezzi).                                  |\n",
    "| Healthcare                             | 68%                   | Diagnostics and drug discovery; 38% for specific tools like diagnosis (PRNewswire/DemandSage average).     |\n",
    "| Retail                                 | 65%                   | Personalization and inventory; 80% of executives planning full automation (PRNewswire/DemandSage).         |\n",
    "| Energy                                 | 41%                   | Smart grids and optimization; lower due to regulatory hurdles (Zebracat).                                  |\n",
    "| Cloud Computing/Data Analytics (IT/Tech)| 83%                  | Core infrastructure for AI; highest adoption (Mezzi/Zebracat).                                             |\n",
    "\n",
    "---  \n",
    "\n",
    "### Core Concepts  \n",
    "\n",
    "**The Agent-Environment Interaction Loop**  \n",
    "\n",
    "The foundation of agent theory rests on the agent-environment interaction loop, a continuous cycle that defines how agents operate:  \n",
    "\n",
    "**Perception**  \n",
    "\n",
    "Agents gather information about their environment through sensors. These might be:  \n",
    "\n",
    "- **Physical Sensors**: Cameras, microphones, temperature gauges, GPS units\n",
    "- **Digital Sensors**: Network monitors, database queries, user input interfaces\n",
    "- **Abstract Sensors**: Market data feeds, social media streams, system logs  \n",
    "\n",
    "**Cognition/Reasoning**  \n",
    "\n",
    "Once an agent perceives its environment, it must **process and interpret** this information. This involves:  \n",
    "\n",
    "- **State representation**: Converting raw sensor data into an internal model of the world\n",
    "- **Goal evaluation**: Determining what needs to be achieved\n",
    "- **Decision making**: Choosing which action to take next\n",
    "- **Learning**: Updating knowledge based on experience  \n",
    "\n",
    "**Action**  \n",
    "\n",
    "Finally, agents execute **actions** through **actuators**:  \n",
    "\n",
    "- **Physical actuators**: Motors, speakers, robotic arms, displays\n",
    "- **Digital actuators**: Database updates, network messages, file ops\n",
    "- **Abstract actuators**: Recommendations, alerts, financial transactions  \n",
    "\n",
    "Tis perception-cognition-action cycle repeats continuously, creating a feedback loop where actions influence the environment, which in turn affects future perceptions.  \n",
    "\n",
    "**Autonomy**  \n",
    "\n",
    "**Autonomous agents** operate independently without direct human control. They make their own decisions about when and how to act. However, autonomy exists on a spectrum:  \n",
    "\n",
    "- **Full Autonomy**: Complete independence (rare in practice)\n",
    "- **Semi-autonomy**: Independent operation with occasional human oversight\n",
    "- **Supervised autonomy**: Continuous human monitoring with intervention capability  \n",
    "\n",
    "**Reactivity**  \n",
    "\n",
    "**Reactive agents** respond promptly to environmental changes. A reactive thermostat, for example, immediately adjusts heating when temperature deops below a threshold. Reactivity ensures agents remain responsive to their environment rather than getting stuck in endless deliberation.  \n",
    "\n",
    "**Proactivity**  \n",
    "\n",
    "**Proactive agents** take initiative to achieve their goals rather than simply reacting to events. They can plan ahead, anticipate problems, and take preventive actions. A proactive email agent might notice you often delete emails from certain senders and automatically create filters to manage them.  \n",
    "\n",
    "**Social Ability**:  \n",
    "\n",
    "**Social agents** can interact and coordinate with other agents or humans. This involves communication protocols, negotiation strategies, and cooperation mechanisms. Multi-agent systems rely heavily on social abilities to avoid conflicts and achieve collective goals.  \n",
    "\n",
    "#### Simple Reflex Agents  \n",
    "\n",
    "The most basic type, **simple reflex agents** follow condition-action rules: \"If condition X is true, then perform action Y.\" They have no memory of past states and base decisions solely on current perceptions.  \n",
    "\n",
    "**Example**: A simple fire alarm agent  \n",
    "\n",
    "```\n",
    "IF smoke_detected = True THEN sound_alarm()\n",
    "IF smoke_detected = False THEN remain_silent()\n",
    "```\n",
    "\n",
    "**Limitations**: Cannot handle situations requiring historical context or multi-step reasoning.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28026df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial system status: unknown\n",
      "System status updated: normal\n",
      "Final system status: normal\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Initial system status\n",
    "status = \"unknown\"\n",
    "print(f\"Initial system status: {status}\")\n",
    "\n",
    "# Simulate environment condition\n",
    "smoke_detected = random.choice([True, False])\n",
    "if smoke_detected:\n",
    "    status = \"emergency\"\n",
    "    print(f\"System status updated: {status}\")\n",
    "else:\n",
    "    if not smoke_detected:\n",
    "        status = \"normal\"\n",
    "        print(f\"System status updated: {status}\")\n",
    "print(f\"Final system status: {status}\")\n",
    "\n",
    "# Initial system status: unknown\n",
    "# System status updated: emergency\n",
    "# System status updated: normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cbb028",
   "metadata": {},
   "source": [
    "#### Model-Based Reflex Agents  \n",
    "\n",
    "**Model-based reflex agents** maintain an internal model of the world that tracks aspects of the environment not directly observable. They combine current perceptions with their internal model to make better decisions. \n",
    "\n",
    "**Example**: A fire alarm that maintains a system log of the environment conditions (temperature, humidity, detection level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e654de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceived smoke: False, Agent action: Standby\n"
     ]
    }
   ],
   "source": [
    "# Model-based reflex agent for a simple environment\n",
    "class ReflexAgent:\n",
    "    def __init__(self):\n",
    "        self.state = \"unknown\"\n",
    "\n",
    "    def perceive(self, smoke):\n",
    "        if smoke:\n",
    "            self.state = \"emergency\"\n",
    "        else:\n",
    "            self.state = \"normal\"\n",
    "\n",
    "    def act(self):\n",
    "        if self.state == \"emergency\":\n",
    "            return \"Sound Alarm\"\n",
    "        elif self.state == \"normal\":\n",
    "            return \"Standby\"\n",
    "        else:\n",
    "            return \"No Action\"\n",
    "        \n",
    "# Create an agent instance\n",
    "agent = ReflexAgent()\n",
    "\n",
    "# Simulate perception and action\n",
    "smoke = random.choice([True, False])\n",
    "agent.perceive(smoke)\n",
    "action = agent.act()\n",
    "print(f\"Perceived smoke: {smoke}, Agent action: {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899253b",
   "metadata": {},
   "source": [
    "#### Goal-Based Agents  \n",
    "\n",
    "**Goal-based agents** make decisions by considering how different actions will help achieve their goals. They can reason about future consequences and choose actions that bring them closer to their objectives.\n",
    "\n",
    "**Example**: A navigation agent knows its goal is to reach a destination (no threat of fire) and evaluates which location is marked safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a15dc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent action: Find alternative route\n"
     ]
    }
   ],
   "source": [
    "# Goal-based agent for navigation\n",
    "\n",
    "class GoalBasedAgent:\n",
    "    def __init__(self, goal):\n",
    "        self.goal = goal\n",
    "        self.current_location = \"Home\"\n",
    "\n",
    "    def perceive(self, location_status):\n",
    "        self.location_status = location_status\n",
    "\n",
    "    def decide_action(self):\n",
    "        if self.location_status.get(self.current_location) == \"safe\":\n",
    "            return f\"Proceed to {self.goal}\"\n",
    "        else:\n",
    "            return \"Find alternative route\"\n",
    "        \n",
    "# Create a goal-based agent instance\n",
    "goal_agent = GoalBasedAgent(goal=\"Hospital\")\n",
    "\n",
    "# Simulate random perception of location status\n",
    "location_status = {\"Home\": random.choice([\"safe\", \"unsafe\"]), \"Hospital\": random.choice([\"safe\", \"unsafe\"])}\n",
    "goal_agent.perceive(location_status)\n",
    "action = goal_agent.decide_action()\n",
    "print(f\"Agent action: {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490a828",
   "metadata": {},
   "source": [
    "#### Utility-Based Agents  \n",
    "\n",
    "Utility-based agents go beyond simple goal achievement by optimizing for multiple, potentially competing objectives. They use a utility function that assigns numerical values to different outcomes, allowing them to make trade-offs.\n",
    "\n",
    "Example: A rideshare matching agent balances multiple factors: minimizing passenger wait time, reducing driver idle time, evaluating safe locations, and maximizing revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bbcc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent action: Accept Ride\n"
     ]
    }
   ],
   "source": [
    "# Example: A rideshare matching agent that balances multiple factors\n",
    "\n",
    "class UtilityBasedAgent:\n",
    "    def __init__(self):\n",
    "        self.utility_function = {\n",
    "            \"minimize_wait_time\": 0.4,\n",
    "            \"reduce_driver_idle\": 0.3,\n",
    "            \"evaluate_safe_locations\": 0.2,\n",
    "            \"maximize_revenue\": 0.1\n",
    "        }\n",
    "\n",
    "    def perceive(self, environment_factors):\n",
    "        self.environment_factors = environment_factors\n",
    "\n",
    "    def decide_action(self):\n",
    "        utility_score = sum(self.utility_function[factor] * self.environment_factors.get(factor, 0) for factor in self.utility_function)\n",
    "        if utility_score > 0.5:\n",
    "            return \"Accept Ride\"\n",
    "        else:\n",
    "            return \"Decline Ride\"\n",
    "        \n",
    "# Create a utility-based agent instance\n",
    "utility_agent = UtilityBasedAgent()\n",
    "\n",
    "# Simulate random perception of environment factors\n",
    "environment_factors = {\n",
    "    \"minimize_wait_time\": random.uniform(0, 1),\n",
    "    \"reduce_driver_idle\": random.uniform(0, 1),\n",
    "    \"evaluate_safe_locations\": random.uniform(0, 1),\n",
    "    \"maximize_revenue\": random.uniform(0, 1)\n",
    "}\n",
    "utility_agent.perceive(environment_factors)\n",
    "action = utility_agent.decide_action()\n",
    "print(f\"Agent action: {action}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
