{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2463e0d1",
   "metadata": {},
   "source": [
    "# Deep Learning: PyTorch Tutorials\n",
    "\n",
    "PyTorch is an open-source machine learning framework developed by Meta AI, known for accelerating the path from research prototyping to production deployment. It’s beginner-friendly due to its Pythonic syntax and dynamic computation graph, which allows flexible model design and easy debugging. PyTorch supports GPU acceleration for faster computations and includes libraries like torchvision for computer vision tasks, making it ideal for deep learning applications such as image classification and natural language processing.\n",
    "\n",
    "**Key Features**:  \n",
    "- Dynamic Computation Graphs\n",
    "- Tensors: Multi-dimensional arrays optimized for CPU and GPU operations\n",
    "- Autograd: Automatic differentiation for computing gradients during training.\n",
    "- Neural Network Modules: Tools like `nn.Module` simplify model construction.\n",
    "- Ecosystem: Libraries for vision (`torchvision`), text (`torchtext`), and audio (`torchaudio`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a46fe44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Verify the installation\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)  # Displays PyTorch version\n",
    "print(torch.cuda.is_available())  # Checks for GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b90479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from list: tensor([1, 2, 3])\n",
      "Zeros tensor: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Matrix multiplication: tensor([[1.7769, 1.9634],\n",
      "        [1.7769, 1.9634]])\n",
      "Reshaped tensor: tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "# Understanding Tensors\n",
    "\n",
    "# Tensors are PyTorch’s core data structure, similar to NumPy arrays \n",
    "# but with GPU support and autograd capabilities. They represent multi-dimensional \n",
    "# arrays used for model inputs, outputs, and weights. Tensors support over 300 \n",
    "# mathematical operations, optimized for performance in compiled C++ code.\n",
    "\n",
    "# Creating and Manipulating Tensors\n",
    "\n",
    "# You can create tensors from lists, arrays, or random values, and perform operations \n",
    "# like addition, multiplication, and reshaping. Tensors can be moved to GPUs for faster \n",
    "# computations, crucial for deep learning tasks.\n",
    "\n",
    "# Create tensors\n",
    "tensor_list = torch.tensor([1, 2, 3])  # From a list\n",
    "zeros_tensor = torch.zeros(2, 3)       # 2x3 tensor of zeros\n",
    "ones_tensor = torch.ones(2, 3)         # 2x3 tensor of ones\n",
    "random_tensor = torch.rand(2, 3)       # 2x3 random tensor\n",
    "\n",
    "# Basic operations\n",
    "sum_tensor = tensor_list + 1           # Add scalar\n",
    "product_tensor = tensor_list * 2       # Multiply by scalar\n",
    "matmul_result = torch.matmul(ones_tensor, random_tensor.t())  # Matrix multiplication\n",
    "\n",
    "# Reshape tensor\n",
    "reshaped_tensor = tensor_list.view(3, 1)  # Reshape to 3x1\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tensor_gpu = tensor_list.to(device)\n",
    "\n",
    "print(\"Tensor from list:\", tensor_list)\n",
    "print(\"Zeros tensor:\", zeros_tensor)\n",
    "print(\"Matrix multiplication:\", matmul_result)\n",
    "print(\"Reshaped tensor:\", reshaped_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c9716",
   "metadata": {},
   "source": [
    "Tensors are the data structure that makes deep learning tractable. Their ability to handle high-dimensional data, track gradients, and leverage hardware acceleration (via CUDA) is what allows complex models to process images, text, or time-series data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0683d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of y with respect to x: tensor(7.)\n"
     ]
    }
   ],
   "source": [
    "# What is Autograd?\n",
    "\n",
    "# Autograd is PyTorch’s automatic differentiation engine, which tracks operations \n",
    "# on tensors to compute gradients automatically. This simplifies backpropagation, \n",
    "# enabling neural networks to learn by adjusting weights based on the loss function’s \n",
    "# gradients.\n",
    "\n",
    "# How Autograd Works\n",
    "\n",
    "# When a tensor has requires_grad=True, PyTorch records its operations in a computation \n",
    "# graph. Calling .backward() computes gradients for all tensors in the graph, which are \n",
    "# stored in the .grad attribute. This is essential for optimizing model parameters \n",
    "# during training.\n",
    "\n",
    "# Create a tensor with requires_grad=True\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Define a simple function\n",
    "y = x ** 2 + 3 * x + 1\n",
    "\n",
    "# Compute gradients\n",
    "y.backward()\n",
    "\n",
    "# Print gradient (dy/dx = 2x + 3, at x=2, gradient = 7)\n",
    "print(\"Gradient of y with respect to x:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ece1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks with nn.Module\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 10)  # Input: 4 features, Output: 10 units\n",
    "        self.fc2 = nn.Linear(10, 3)  # Output: 3 classes (iris dataset)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # ReLU activation\n",
    "        x = self.fc2(x)          # Output logits\n",
    "        return x\n",
    "\n",
    "# Instantiate and test the model\n",
    "model = SimpleNN()\n",
    "sample_input = torch.rand(1, 4)  # Batch of 1, 4 features\n",
    "output = model(sample_input)\n",
    "print(\"Model output shape:\", output.shape)  # Should be [1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0550f797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.0595\n",
      "Epoch [20/100], Loss: 0.9075\n",
      "Epoch [30/100], Loss: 0.7088\n",
      "Epoch [40/100], Loss: 0.5620\n",
      "Epoch [50/100], Loss: 0.4821\n",
      "Epoch [60/100], Loss: 0.4325\n",
      "Epoch [70/100], Loss: 0.3846\n",
      "Epoch [80/100], Loss: 0.3456\n",
      "Epoch [90/100], Loss: 0.3078\n",
      "Epoch [100/100], Loss: 0.2814\n",
      "Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Code Example: Building, Training, and Evaluating on the Iris Dataset\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Load and preprocess iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Define model, loss, and optimizer\n",
    "model = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'iris_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
